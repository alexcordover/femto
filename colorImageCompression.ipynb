{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import colorsys\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import shuffle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#converts 1d array into a 2d array where rows are w long\n",
    "def arr_reshape(arr,w):\n",
    "    l = len(arr)\n",
    "    p = math.ceil(l/w)\n",
    "    out = []\n",
    "    for i in range(p):\n",
    "        out.append(arr[i*w:(i+1)*w])\n",
    "    return out\n",
    "\n",
    "#remove every nth column\n",
    "def remove_col(arr,n_col):\n",
    "    res = []\n",
    "    r_max = len(arr)\n",
    "    c_max = len(arr[0])\n",
    "    for i in range(r_max):\n",
    "        row = []\n",
    "        row.append(arr[i][0])\n",
    "        for j in range(1,c_max-1):\n",
    "            if ((j+1)%n_col != 0):\n",
    "                row.append(arr[i][j])\n",
    "        row.append(arr[i][c_max-1])\n",
    "        res.append(row)\n",
    "    return res\n",
    "#remove every nth row\n",
    "def remove_row(arr,n_row):\n",
    "    res = []\n",
    "    r_max = len(arr)\n",
    "    res.append(arr[0])\n",
    "    for i in range(1,r_max-1):\n",
    "        if((i+1)%n_row != 0 ):\n",
    "            res.append(arr[i])\n",
    "    res.append(arr[r_max-1])\n",
    "    return res\n",
    "#re-add columns removed\n",
    "def add_col(arr,w,n_col): \n",
    "    res = []\n",
    "    h = len(arr)\n",
    "    l = len(arr[0])\n",
    "    for i in range(h):\n",
    "        row = [] \n",
    "        arr_i=1\n",
    "        row.append(arr[i][0])\n",
    "        for j in range(1,w-1):\n",
    "            if((j+1)%n_col == 0):\n",
    "                row.append((np.array(arr[i][arr_i-1])+np.array(arr[i][arr_i]))/2)\n",
    "            else:\n",
    "                row.append(arr[i][arr_i])\n",
    "                arr_i+=1\n",
    "        row.append(arr[i][l-1])\n",
    "        res.append(row)\n",
    "    return res\n",
    "def add_row(arr,h,n_row):\n",
    "    res =[]\n",
    "    res.append(arr[0])\n",
    "    arr_i = 1\n",
    "    for i in range(1,h-1):\n",
    "        if((i+1)%n_row == 0 ):\n",
    "            res.append((np.array(arr[arr_i-1])+np.array(arr[arr_i]))/2)\n",
    "        else:\n",
    "            res.append(arr[arr_i])\n",
    "            arr_i+=1\n",
    "    res.append(arr[len(arr)-1])\n",
    "    return res\n",
    "#return a,b,c components we use for reconstruction\n",
    "def svd_recon_components(arr,num_eigenvecs,a_decimals,b_decimals,c_decimals):\n",
    "    u, s, v = np.linalg.svd(arr)\n",
    "    return [np.round(u[:, :num_eigenvecs],decimals=a_decimals),np.round(s[:num_eigenvecs],decimals=b_decimals),np.round(v[:num_eigenvecs, :],decimals=c_decimals)]\n",
    "\n",
    "#runs kmeans on a matrix and creates a kstring\n",
    "def kmeans_serialize(arr,n_clusts,num_decimals):\n",
    "    #changing 1d array to 2d array in order run kmeans instead of using some sort of binning algorithm\n",
    "    sample = list(zip(shuffle(arr.flatten(), random_state=0)[:1500],[0]*1500))\n",
    "    kmeans = KMeans(n_clusters=n_clusts, random_state=0).fit(sample)\n",
    "    clusters = np.round(kmeans.cluster_centers_,decimals=num_decimals)[:,0]\n",
    "    k= list(map(lambda x: kmeans.predict(list(map(lambda y: [y,0],x))),arr))\n",
    "    k_string = ''.join(list(map(lambda x: ''.join(list(map(chr,x))),k)))\n",
    "    return clusters.tolist(),k_string\n",
    "\n",
    "#changes kstrings back to into component matrix. THIS WOULD ESSENTIALLY RUN IN THE BROWSER\n",
    "def kmeans_unserializer(kstring,clusters,w):\n",
    "    t= []\n",
    "    for k in kstring:\n",
    "        t.append(clusters[ord(k)])\n",
    "    return arr_reshape(t,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Declaring global vars\n",
    "h_eigenvecs,s_eigenvecs,v_eigenvecs = (256,256,512) #number of eigenvectors to use for hue,saturation,value (respectively)\n",
    "decimals_a,decimals_b,decimals_c =(4,2,5) #number of decimal places to use for a,b,c reconstruction components\n",
    "kstring_clusters =128\n",
    "img_name ='image11.TIFF'\n",
    "num_color_clusters = 256\n",
    "nth_col = 4 #remove every nth col #make sure image width is not divisible by number reason:reeeeeeeeeee\n",
    "nth_row = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2456, 3680, 3)\n",
      "CPU times: user 2min 9s, sys: 8.24 s, total: 2min 18s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Read in rgb image. Tested and worked on TIFF and jpg.\n",
    "img = misc.imread('images/'+img_name).astype(float)\n",
    "h, w, d = original_shape = tuple(img.shape)\n",
    "print(original_shape)\n",
    "assert d == 3 #Basically we want to make sure we have an rgb image not a rgba one\n",
    "\n",
    "#Doing a double map with colorsys.rgb_to_hsv is slow ;__; so we'll kmeans and then predict\n",
    "img_arr_sample = shuffle(np.reshape(img, (w * h, d)), random_state=0)[:1000]\n",
    "color_kmeans = KMeans(n_clusters=num_color_clusters, random_state=0).fit(img_arr_sample)\n",
    "color_clusters = np.array(list(map(lambda x: colorsys.rgb_to_hsv(x[0]/255,x[1]/255,x[2]/255),color_kmeans.cluster_centers_)))\n",
    "\n",
    "#use predict to get hsv vals and then reshape in order to column extract hsv\n",
    "hsv_arr = np.reshape(np.array(list(map(lambda x: color_clusters[x],list(map(color_kmeans.predict,img))))), (w * h, d))\n",
    "\n",
    "#column extract hue,sat,val arrays and reshape; then remove columns and rows\n",
    "h_arr = remove_row(remove_col(arr_reshape(hsv_arr[:,0],w),nth_col),nth_row)\n",
    "s_arr = remove_row(remove_col(arr_reshape(hsv_arr[:,1],w),nth_col),nth_row)\n",
    "v_arr = remove_row(remove_col(arr_reshape(hsv_arr[:,2],w),nth_col),nth_row)\n",
    "\n",
    "#svd components needed for reconstruction\n",
    "h_a,h_b,h_c = svd_recon_components(h_arr,h_eigenvecs,decimals_a,decimals_b,decimals_c)\n",
    "s_a,s_b,s_c = svd_recon_components(s_arr,s_eigenvecs,decimals_a,decimals_b,decimals_c)\n",
    "v_a,v_b,v_c = svd_recon_components(v_arr,v_eigenvecs,decimals_a,decimals_b,decimals_c)\n",
    "\n",
    "#dict for json\n",
    "js_dict={}\n",
    "js_dict['shape'] = [w,h]\n",
    "js_dict['remove'] = [nth_col,nth_row]\n",
    "#kmeans compression, compress a and c comps.\n",
    "h_a_cluster,h_a_kstring = kmeans_serialize(h_a,kstring_clusters,decimals_a)\n",
    "h_c_cluster,h_c_kstring = kmeans_serialize(h_c,kstring_clusters,decimals_c)\n",
    "js_dict['h_a_kstring'] = h_a_kstring\n",
    "js_dict['h_a_cluster'] = h_a_cluster\n",
    "js_dict['h_b'] = h_b.tolist()\n",
    "js_dict['h_c_kstring'] = h_c_kstring\n",
    "js_dict['h_c_cluster'] = h_c_cluster\n",
    "\n",
    "s_a_cluster,s_a_kstring = kmeans_serialize(s_a,kstring_clusters,decimals_a)\n",
    "s_c_cluster,s_c_kstring = kmeans_serialize(s_c,kstring_clusters,decimals_c)\n",
    "js_dict['s_a_kstring'] = s_a_kstring\n",
    "js_dict['s_a_cluster'] = s_a_cluster\n",
    "js_dict['s_b'] = s_b.tolist()\n",
    "js_dict['s_c_kstring'] = s_c_kstring\n",
    "js_dict['s_c_cluster'] = s_c_cluster\n",
    "\n",
    "v_a_cluster,v_a_kstring = kmeans_serialize(v_a,kstring_clusters,decimals_a)\n",
    "v_c_cluster,v_c_kstring = kmeans_serialize(v_c,kstring_clusters,decimals_c)   \n",
    "js_dict['v_a_kstring'] = v_a_kstring\n",
    "js_dict['v_a_cluster'] = v_a_cluster\n",
    "js_dict['v_b'] = v_b.tolist()\n",
    "js_dict['v_c_kstring'] = v_c_kstring\n",
    "js_dict['v_c_cluster'] = v_c_cluster\n",
    "with open('new_data.txt', 'w') as outfile:\n",
    "    json.dump(js_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "h_a_recon =kmeans_unserializer(h_a_kstring,h_a_cluster,h_eigenvecs)\n",
    "h_c_recon =kmeans_unserializer(h_c_kstring,h_c_cluster,len(h_c[0]))\n",
    "s_a_recon =kmeans_unserializer(s_a_kstring,s_a_cluster,s_eigenvecs)\n",
    "s_c_recon =kmeans_unserializer(s_c_kstring,s_c_cluster,len(s_c[0]))\n",
    "v_a_recon = kmeans_unserializer(v_a_kstring,v_a_cluster,v_eigenvecs)\n",
    "v_c_recon =kmeans_unserializer(v_c_kstring,v_c_cluster,len(v_c[0]))\n",
    "\n",
    "h_recon = np.matrix(h_a_recon) * np.diag(h_b) * np.matrix(h_c_recon)\n",
    "s_recon = np.matrix(s_a_recon) * np.diag(s_b) * np.matrix(s_c_recon)\n",
    "v_recon = np.matrix(v_a_recon) * np.diag(v_b) * np.matrix(v_c_recon)\n",
    "\n",
    "img_arr_recon = list(zip(np.asarray(h_recon),np.asarray(s_recon),np.asarray(v_recon)))\n",
    "img_arr_recon = list(map(lambda a:list(zip(a[0],a[1],a[2])),img_arr_recon))\n",
    "img_arr_recon = list(map(lambda x:list(map(lambda y: colorsys.hsv_to_rgb(y[0],y[1],y[2]),x)),img_arr_recon))\n",
    "img_arr_recon = add_row(add_col(img_arr_recon,w,nth_col),h,nth_row)\n",
    "misc.imsave('images_out/'+img_name,np.asarray(img_arr_recon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538880"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
